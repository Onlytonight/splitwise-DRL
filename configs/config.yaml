defaults:
  - cluster: dgx-a100
  - router: noop
  - arbiter: noop
  - hardware_repo: default
  - model_repo: default
  - orchestrator_repo: default
  - performance_model: constant
  - power_model: constant
  - applications: solo
  - trace: test_trace
  - start_state: orca
  - override hydra/launcher: ray
  - _self_

end_time: 144
debug: False
seed: 0
trace_list:
  - traces/burst_144/day_30.csv
#  - traces/rr_conv_30_50.csv

trace_epochs: 1  # 单个 trace 的循环次数（当使用 trace_list 时，此参数用于控制整个列表的循环次数）
trace_list_repeats: 1000  # trace_list 的循环次数
# 直接指定要加载的 SAC 模型 checkpoint 完整路径（相对当前运行目录或绝对路径）
#model_path: C:\Data\project\splitwise-DRL\cp/SAC_66000_20260115_122325.pth

# SAC 训练参数
min_steps_before_training: 0  # 开始训练前的最小步数
exclude_feature: null  # 要排除的 feature，可选值: queue, none_count, instance_count, timestamp, rps, rps_delta, length, rate, p_ins_pending_token，null 表示不排除任何 feature

choices: ${hydra:runtime.choices}
#output_dir: results/${seed}/${start_state.state_type}/${trace.filename}/${cluster.servers.0.count}_${cluster.servers.1.count}/${applications.0.model_architecture}/${applications.0.scheduler}
output_dir: results/state/${exclude_feature}

hydra:
  # changes the cwd to the output directory
  run:
    dir: ${output_dir}
  sweep:
    dir: ""
    subdir: ${output_dir}
  job:
    chdir: True
  launcher:
    ray:
      init:
        address: "127.0.0.1:6379"
        object_store_memory: null
