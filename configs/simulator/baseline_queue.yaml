# 基于队列长度的基线策略配置
algorithm: baseline_queue

# 决策参数
decision_interval: 2  # 决策间隔（秒）

# 状态特征配置
enabled_features:
  - queue
  - none_count
  - instance_count
  - timestamp
  - rps
  - rps_delta
#  - length
#  - rate
#  - util_mem
#  - draining
#  - p_ins_pending_token
#  - queue_delta



stack_size: 4  # 状态堆叠的时间窗大小

# 奖励函数权重（用于评估）
reward_weights:
  w_cost: 0.5
  w_slo: 0.5
  w_switch: 0.1
  w_util: 1.0
  w_congestion: 1.0
  w_stability: 0.0

# 动作执行参数
action_scale_step: 5
action_mig_step: 3
min_instances_per_pool: 1
max_total_instances: 100

# 经验池保存配置（用于离线RL/预训练）
save_replay_buffer: false              # 是否保存经验池
replay_buffer_path: "data/replay_buffer_queue.npz"  # 经验池保存路径
clear_replay_buffer_on_start: false   # 启动时是否清空已有经验池（false=追加模式，true=覆盖模式）

# 基于队列长度的策略参数
policy_config:
  # Prompt队列阈值（token数）
  prompt_queue_upper: 1000  # 队列长度超过1000 tokens时扩容
  prompt_queue_lower: 100   # 队列长度低于100 tokens时缩容
  
  # Token队列阈值（token数）
  token_queue_upper: 5000   # 队列长度超过5000 tokens时扩容
  token_queue_lower: 500    # 队列长度低于500 tokens时缩容
  
  # 扩缩容步长
  scale_step: 5  # 每次扩/缩容的实例数
  
  # 实例数限制
  min_instances_per_pool: 1
  max_total_instances: 200
